{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_given import *\n",
    "from preprocess import *\n",
    "from helpers import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data with helpers_given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"dataset/\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_col = x_train.shape[1]\n",
    "nb_rows = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_01 = convert_minus1_to_0(y_train)\n",
    "print(\"Number of people with MICHD: \" + str(y_01[y_01==1].shape))\n",
    "print(\"Number of people without MICHD: \" + str(y_01[y_01==0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/x_train.csv', 'r') as f:\n",
    "    features_string = f.readline()\n",
    "    features = features_string.split(',')\n",
    "features = features[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nans = np.zeros(nb_col)\n",
    "for i, col in enumerate(x_train.T):\n",
    "    nb_nans[i] = np.count_nonzero(np.isnan(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_nans = number_of_NaNs(features, x_train)\n",
    "reduced_data, reduced_features, Removed_features = removing_features(nb_nans, features, x_train, threshold=0.2)\n",
    "#need to apply the same transfo to x_test\n",
    "reduced_test = np.delete(x_test, Removed_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature correlation dictionary\n",
    "feature_correlation_dict = create_dictionary_from_correlation(reduced_data,reduced_features,0.6)\n",
    "\n",
    "max_corrr_feature_dict = {}\n",
    "\n",
    "for key, val in feature_correlation_dict.items():\n",
    "    max_corrr_feature_dict[key] = len(val)\n",
    "\n",
    "# Sort the dictionary by value in descending order\n",
    "max_corrr_feature_dict = {k: v for k, v in sorted(max_corrr_feature_dict.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = nan_corrcoef(reduced_data[:, 80:100])\n",
    "# plt.figure(figsize=(20,20))\n",
    "sns.heatmap(correlations, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = []\n",
    "for key in max_corrr_feature_dict.keys():\n",
    "    features_to_drop.append(key)\n",
    "    if len(features_to_drop) == 30:\n",
    "        break\n",
    "\n",
    "# Define features to keep\n",
    "features_to_keep = []\n",
    "for feature in reduced_features:\n",
    "    if feature not in features_to_drop:\n",
    "        features_to_keep.append(feature)\n",
    "\n",
    "# Also replace some features with their calculated counterparts\n",
    "origin_calculated_features = {\n",
    "    'WEIGHT2' : 'WTKG3',\n",
    "    'HEIGHT3' : 'HTM4',\n",
    "    'ALCDAY5' : '_DRNKWEK',\n",
    "    'FRUITJU1' : 'FTJUDA1_',\n",
    "    'FRUIT1' : 'FRUTDA1_',\n",
    "    'FVBEANS' : 'BEANDAY_',\n",
    "    'FVGREEN' : 'GRENDAY_',\n",
    "    'FVORANG' : 'ORNGDAY_',\n",
    "    'VEGETAB1' : 'VEGEDA1_',\n",
    "    'STRENGTH' : 'STRFREQ_'\n",
    "}\n",
    "\n",
    "# In features_to_keep replace the key of origin_calculated_features with the value\n",
    "for key, val in origin_calculated_features.items():\n",
    "    for i, feature in enumerate(features_to_keep):\n",
    "        if key == feature:\n",
    "            features_to_keep[i] = val\n",
    "\n",
    "# Drop duplicates\n",
    "features_to_keep = list(set(features_to_keep))\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_features_indices = []\n",
    "selected_features_indices_original = []\n",
    "for feature in features_to_keep:\n",
    "    selected_features_indices.append(reduced_features.index(feature))\n",
    "    selected_features_indices_original.append(features.index(feature))\n",
    "\n",
    "selected_features_indices = sorted(selected_features_indices)\n",
    "selected_features_indices_original = sorted(selected_features_indices_original)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with keeping the features that are in the selected_features_indices\n",
    "reduced_data = reduced_data[:,selected_features_indices]\n",
    "reduced_test = reduced_test[:,selected_features_indices]\n",
    "\n",
    "# Also remove the features from the reduced_features list\n",
    "reduced_features_2 = []\n",
    "for feature in reduced_features:\n",
    "    if feature in features_to_keep:\n",
    "        reduced_features_2.append(feature)\n",
    "\n",
    "# Remove redundant features\n",
    "redundant_features = [ 'FMONTH','IDATE','IMONTH','IDAY','IYEAR', 'SEQNO', '_STATE', '_PSU', ]\n",
    "# Get the indices of these features\n",
    "redundant_features_indices = []\n",
    "redundant_features_indices_original = []\n",
    "for feature in redundant_features:\n",
    "    if feature in reduced_features_2:\n",
    "        redundant_features_indices.append(reduced_features_2.index(feature))\n",
    "        redundant_features_indices_original.append(features.index(feature))\n",
    "\n",
    "# Create a new dataset with removing the features that are in the selected_features_indices\n",
    "reduced_data = np.delete(reduced_data, redundant_features_indices, 1)\n",
    "reduced_features_2 = [reduced_features_2[i] for i in range(len(reduced_features_2)) if i not in redundant_features_indices]\n",
    "reduced_test = np.delete(reduced_test, redundant_features_indices, 1)\n",
    "selected_indices_original = [i for i in selected_features_indices_original if i not in redundant_features_indices_original]\n",
    "\n",
    "# Replace nine values with NaNs\n",
    "replace_nine_with_nan(reduced_data)\n",
    "replace_nine_with_nan(reduced_test)\n",
    "\n",
    "# Replace seven values with NaNs\n",
    "replace_seven_with_nan(reduced_data)\n",
    "replace_seven_with_nan(reduced_test)\n",
    "\n",
    "# Replace 99 values with NaNs\n",
    "replace_99_with_nan(reduced_data)\n",
    "replace_99_with_nan(reduced_test)\n",
    "\n",
    "# For the _DRNKWEK feature, replace 9990 with NaN\n",
    "for i in range(reduced_data.shape[0]):\n",
    "    if reduced_data[i, reduced_features_2.index('_DRNKWEK')] == 9990:\n",
    "        reduced_data[i, reduced_features_2.index('_DRNKWEK')] = np.nan\n",
    "for i in range(reduced_test.shape[0]):\n",
    "    if reduced_test[i, reduced_features_2.index('_DRNKWEK')] == 9990:\n",
    "        reduced_test[i, reduced_features_2.index('_DRNKWEK')] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_indices_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "reduced_data = clean_outliers_modified(reduced_data)\n",
    "reduced_test = clean_outliers_modified(reduced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with medians\n",
    "reduced_median = replace_nans(reduced_data, method='median')\n",
    "reduced_median_test = replace_nans(reduced_test, method='median')\n",
    "\n",
    "# Standardize the data\n",
    "std_x_med = standardize_data(reduced_median)\n",
    "std_test_med = standardize_data(reduced_median_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "sns.heatmap(np.corrcoef(reduced_median[:, 70:90].T), cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "NB_COL = std_x_med.shape[1] # corresponds to 'D' = number of features\n",
    "NB_ROWS = std_x_med.shape[0] # corresponds to 'N' = number of observations/respondents\n",
    "print(\"Number of features left: \" + str(NB_COL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV on the two hyperparameters degree and lambda on regularized logistic regression adding polynomial terms\n",
    "seed = 12\n",
    "degrees = [1]\n",
    "k_fold = 4\n",
    "lambdas = np.linspace(0.1, 0.9, 33)\n",
    "gamma = 0.5\n",
    "max_iters = 50\n",
    "initial_w = np.zeros(NB_COL)\n",
    "k_indices = build_k_indices(y_01, k_fold, seed)\n",
    "# for each degree, we compute the best lambdas and the associated rmse\n",
    "best_lambdas = []\n",
    "best_F1s = []\n",
    "best_F1s_tr = []\n",
    "best_lambdas_tr = []\n",
    "plot_F1_te = np.zeros((len(degrees),len(lambdas)))\n",
    "# vary degree\n",
    "for degree in degrees:\n",
    "    # cross validation\n",
    "    F1_te = []\n",
    "    F1_tr = []\n",
    "    for lambda_ in lambdas:\n",
    "        F1_te_tmp = []\n",
    "        F1_tr_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            F1_training, F1_test = cross_validation(y_01, std_x_med,initial_w, max_iters, gamma, k_indices, k, lambda_, degree)\n",
    "            F1_te_tmp.append(F1_test)\n",
    "            F1_tr_tmp.append(F1_training)\n",
    "        F1_te.append(np.mean(F1_te_tmp))\n",
    "        F1_tr.append(np.mean(F1_tr_tmp))\n",
    "        plot_F1_te[degrees.index(degree),np.where(lambdas==lambda_)[0][0]] = np.mean(F1_te_tmp)\n",
    "    print(f\" Finished for degree: {degree}\")\n",
    "    ind_lambda_opt = np.argmax(F1_te)\n",
    "    ind_lambda_opt_tr = np.argmax(F1_tr)\n",
    "    best_lambdas.append(lambdas[ind_lambda_opt])\n",
    "    best_lambdas_tr.append(lambdas[ind_lambda_opt_tr])\n",
    "    best_F1s.append(F1_te[ind_lambda_opt])\n",
    "    best_F1s_tr.append(F1_tr[ind_lambda_opt_tr])\n",
    "ind_best =  np.nanargmax(best_F1s)      \n",
    "best_degree = degrees[ind_best]\n",
    "best_lambda = best_lambdas[ind_best]\n",
    "best_F1 = best_F1s[ind_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_degree)\n",
    "print(best_lambda)\n",
    "print(best_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting evolution of training and test F1-score as a function of lambda or degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambdas,F1_te)\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"Evolution of F1-score as a function of lambda\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"F1-score_lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(len(degrees)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(lambdas,plot_F1_te[i,:])\n",
    "    plt.xlabel('Lambda')\n",
    "    plt.ylabel('F1-score')\n",
    "    plt.title(f'F1-score as a function of lambda with polynomial degree = {degrees[i]}')\n",
    "    plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run regularized logistic regression with best param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = build_poly(std_x_med, best_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_reg, loss_reg = reg_logistic_regression(y_01, tx, initial_w = np.zeros(tx.shape[1]), max_iters = 100, gamma = 0.5, lambda_ = best_lambda)\n",
    "print(\"(logistic) loss: \" + str(loss_reg))\n",
    "y_reg = convert_0_to_minus1(convert_predict(tx @ w_reg))\n",
    "print(y_reg)\n",
    "# accuracy\n",
    "p_reg = compute_accuracy(y_train, y_reg) #percentage of false predictions\n",
    "print(\"accuracy: \" + str(p_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test = build_poly(std_test_med, best_degree)\n",
    "y_pred = convert_0_to_minus1(convert_predict(tx_test @ w_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, y_pred, \"best_result_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score and accuracy of all methods without hyperparameter finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GD\n",
    "w_mse_gd, loss_mse_gd = mean_squared_error_gd(y_01, std_x_med, initial_w = np.zeros(NB_COL), max_iters = 50, gamma = 0.001)\n",
    "y_mse_gd = convert_predict(std_x_med @ w_mse_gd)\n",
    "print(f\"The F1-score is: {compute_f1(y_01,y_mse_gd)} and the accuracy is : {compute_accuracy(y_01,y_mse_gd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "w_mse_sgd, loss_mse_sgd = mean_squared_error_sgd(y_01, std_x_med, initial_w = np.zeros(NB_COL), max_iters = 50, gamma = 0.001)\n",
    "y_mse_sgd = convert_predict(std_x_med @ w_mse_sgd)\n",
    "print(f\"The F1-score is: {compute_f1(y_01,y_mse_sgd)} and the accuracy is : {compute_accuracy(y_01,y_mse_sgd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares\n",
    "w_ls, loss_ls = least_squares(y_01, std_x_med)\n",
    "y_ls = convert_predict(std_x_med @ w_ls)\n",
    "print(f\"The F1-score is: {compute_f1(y_01,y_ls)} and the accuracy is : {compute_accuracy(y_01,y_ls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "w_rr, loss_rr = ridge_regression(y_01, std_x_med, lambda_ = 0.5)\n",
    "y_rr = convert_predict(std_x_med @ w_rr)\n",
    "print(f\"The F1-score is: {compute_f1(y_01,y_rr)} and the accuracy is : {compute_accuracy(y_01,y_rr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression (GD)\n",
    "w_lrgd, loss_lrgd = logistic_regression(y_01, std_x_med, initial_w = np.zeros(NB_COL), max_iters = 50, gamma = 0.001)\n",
    "y_lrgd = convert_predict(std_x_med @ w_lrgd)\n",
    "print(f\"The F1-score is: {compute_f1(y_01,y_lrgd)} and the accuracy is : {compute_accuracy(y_01,y_lrgd)}\")\n",
    "#log sgd\n",
    "#w_lrsgd, loss_lrsgd = logistic_regression_SGD(y_train, x_train, initial_w = np.zeros(NB_COL), max_iters = 50, gamma = 0.1, lambda_ = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_reg, loss_reg = reg_logistic_regression(y_01, std_x_med, initial_w = np.zeros(NB_COL), max_iters = 50, gamma = 0.001, lambda_ = 0.5)\n",
    "y_reg = convert_predict(std_x_med @ w_reg)\n",
    "print(f\"The F1-score is: {compute_f1(y_01,y_reg)} and the accuracy is : {compute_accuracy(y_01,y_reg)}\")\n",
    "# reg log sgd\n",
    "#w_reg_lrsgd, loss_reg_lrsgd = reg_logistic_regression_SGD(y_train, x_train, initial_w = np.zeros(NB_COL), max_iters = 50, gamma = 0.1, lambda_ = 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
