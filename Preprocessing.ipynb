{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b556e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb178f83",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919ac39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def load_data():\n",
    "    \"\"\"load data.\"\"\"\n",
    "    f = open(f\"dataset/x_train.csv\")\n",
    "    features = f.readline()\n",
    "    feature_names = features.split(',')\n",
    "    data = np.loadtxt(f\"dataset/x_train.csv\", delimiter=\",\", skiprows=1, dtype=str)\n",
    "    return data,feature_names\n",
    "\n",
    "def convert_row_to_float(row):\n",
    "    \"\"\"Convert values in row to float or np.nan.\"\"\"\n",
    "    new_row = []\n",
    "    for item in row:\n",
    "        try:\n",
    "            new_row.append(float(item))\n",
    "        except ValueError:\n",
    "            new_row.append(np.nan)\n",
    "    return np.array(new_row)\n",
    "\n",
    "def convert_all_rows(data):\n",
    "    \"\"\"Convert all rows to float or np.nan.\"\"\"\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        new_data.append(convert_row_to_float(row))\n",
    "    return np.array(new_data)\n",
    "\n",
    "def column_NAN(array):\n",
    "    nan=0\n",
    "    for i in range(len(array)):\n",
    "        if np.isnan(array[i]):\n",
    "                nan += 1\n",
    "    return nan\n",
    "\n",
    "def train_validation_split(data, ratio, seed):\n",
    "    \"\"\"Split data into training and validation set.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data)\n",
    "    split_index = int(len(data) * ratio)\n",
    "    return data[:split_index], data[split_index:]\n",
    "\n",
    "def k_fold_split(data, k, seed):\n",
    "    \"\"\"Split data into k folds.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data)\n",
    "    return np.array_split(data, k)\n",
    "\n",
    "def standardize_data(data):\n",
    "    \"\"\"Standardize data.\"\"\"\n",
    "    mean = np.nanmean(data, axis=0)\n",
    "    std = np.nanstd(data, axis=0)\n",
    "    return (data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36db846",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a230c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data, features = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76aa35",
   "metadata": {},
   "source": [
    "#### Converting to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d03d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_all_rows(numpy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ec284",
   "metadata": {},
   "source": [
    "#### Finding number of NaN for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22bb10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaNs=np.zeros(len(features))\n",
    "for i in features:\n",
    "    NaNs[features.index(i)]=column_NAN(data[:,features.index(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e27a21",
   "metadata": {},
   "source": [
    "#### Removing features with too many NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8627422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Removed_features=[]\n",
    "for i in range(len(NaNs)):\n",
    "    if NaNs[i] > round(len(data))*0.1:\n",
    "        Removed_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d4af3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc92d1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 5.30000e+01, 1.10000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00],\n",
       "       [1.00000e+00, 3.30000e+01, 1.20000e+01, ..., 9.00000e+00,\n",
       "        9.00000e+00,         nan],\n",
       "       [2.00000e+00, 2.00000e+01, 1.00000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00],\n",
       "       ...,\n",
       "       [3.28132e+05, 3.90000e+01, 1.00000e+01, ..., 1.00000e+00,\n",
       "        2.00000e+00, 2.00000e+00],\n",
       "       [3.28133e+05, 3.30000e+01, 1.20000e+01, ..., 1.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00],\n",
       "       [3.28134e+05, 3.20000e+01, 9.00000e+00, ..., 1.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(reduced_data, Removed_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc40ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
