{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "initial_w = np.array([0.5, 1.0])\n",
    "y = np.array([0.1, 0.3, 0.5])\n",
    "tx = np.array([[2.3, 3.2], [1.0, 0.1], [1.4, 2.3]])\n",
    "MAX_ITERS = 2\n",
    "GAMMA = 0.1\n",
    "RTOL = 1e-4\n",
    "ATOL = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answers(w, loss, expected_w, expected_loss):\n",
    "    \"\"\"utility function to check the answer\n",
    "    it raises an exception if one on w or loss is not allclose to the expected value\"\"\"\n",
    "    check_w = np.testing.assert_allclose(loss, expected_loss, rtol=RTOL, atol=ATOL)\n",
    "    check_loss = np.testing.assert_allclose(w, expected_w, rtol=RTOL, atol=ATOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test mse_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with step 0\n",
    "expected_w = np.array([0.413044, 0.875757])\n",
    "expected_loss = 2.959836\n",
    "w, loss = mean_squared_error_gd(y, tx, expected_w, 0, GAMMA)\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_w = np.array([-0.050586, 0.203718])\n",
    "expected_loss = 0.051534\n",
    "\n",
    "w, loss = mean_squared_error_gd(y, tx, initial_w, MAX_ITERS, GAMMA)\n",
    "e = y - tx @ w\n",
    "N = len(y)\n",
    "    # ***************************************************\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test mse_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_loss = 0.844595\n",
    "expected_w = np.array([0.063058, 0.39208])\n",
    "w, loss = mean_squared_error_sgd(y[:1], tx[:1], initial_w, MAX_ITERS, GAMMA)\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_w = np.array([0.218786, -0.053837])\n",
    "expected_loss = 0.026942\n",
    "w, loss = least_squares(y, tx)\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with lambda = 0 (equi to ls)\n",
    "w, loss = ridge_regression(y, tx, 0)\n",
    "expected_loss = 0.026942\n",
    "expected_w = np.array([0.218786, -0.053837])\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda = 1\n",
    "expected_loss = 0.03175\n",
    "expected_w = np.array([0.054303, 0.042713])\n",
    "w, loss = ridge_regression(y, tx, 1.0)\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 step\n",
    "expected_w = np.array([0.463156, 0.939874])\n",
    "y_log = (y > 0.2) * 1.0\n",
    "w, loss = logistic_regression_GD(y_log, tx, expected_w, 0, GAMMA)\n",
    "expected_loss = 1.533694\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4222918656735857\n",
      "[0.37811333 0.87811333]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.0001, atol=1e-08\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference: 0.07393387\nMax relative difference: 0.05483252\n x: array(1.422292)\n y: array(1.348358)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\ML_Project_1\\debug.ipynb Cell 15\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(loss)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(w)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m check_answers(w, loss, expected_w, expected_loss)\n",
      "\u001b[1;32mc:\\ML_Project_1\\debug.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_answers\u001b[39m(w, loss, expected_w, expected_loss):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"utility function to check the answer\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    it raises an exception if one on w or loss is not allclose to the expected value\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     check_w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mtesting\u001b[39m.\u001b[39;49massert_allclose(loss, expected_loss, rtol\u001b[39m=\u001b[39;49mRTOL, atol\u001b[39m=\u001b[39;49mATOL)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     check_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39massert_allclose(w, expected_w, rtol\u001b[39m=\u001b[39mRTOL, atol\u001b[39m=\u001b[39mATOL)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\testing\\_private\\utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[0;32m    858\u001b[0m         err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(remarks)\n\u001b[0;32m    859\u001b[0m         msg \u001b[39m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[0;32m    860\u001b[0m                             verbose\u001b[39m=\u001b[39mverbose, header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m    861\u001b[0m                             names\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m), precision\u001b[39m=\u001b[39mprecision)\n\u001b[1;32m--> 862\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(msg)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.0001, atol=1e-08\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference: 0.07393387\nMax relative difference: 0.05483252\n x: array(1.422292)\n y: array(1.348358)"
     ]
    }
   ],
   "source": [
    "expected_loss = 1.348358\n",
    "expected_w = np.array([0.378561, 0.801131])\n",
    "w, loss = logistic_regression_GD(y_log, tx, initial_w, MAX_ITERS, GAMMA)\n",
    "print(loss)\n",
    "print(w)\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.324268618538655\n",
      "[0.31426356 0.81426356]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.0001, atol=1e-08\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference: 0.02408938\nMax relative difference: 0.01786572\n x: array(1.324269)\n y: array(1.348358)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\ML_Project_1\\debug.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(loss)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(w)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m check_answers(w, loss, expected_w, expected_loss)\n",
      "\u001b[1;32mc:\\ML_Project_1\\debug.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_answers\u001b[39m(w, loss, expected_w, expected_loss):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"utility function to check the answer\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    it raises an exception if one on w or loss is not allclose to the expected value\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     check_w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mtesting\u001b[39m.\u001b[39;49massert_allclose(loss, expected_loss, rtol\u001b[39m=\u001b[39;49mRTOL, atol\u001b[39m=\u001b[39;49mATOL)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     check_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtesting\u001b[39m.\u001b[39massert_allclose(w, expected_w, rtol\u001b[39m=\u001b[39mRTOL, atol\u001b[39m=\u001b[39mATOL)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\testing\\_private\\utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[0;32m    858\u001b[0m         err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(remarks)\n\u001b[0;32m    859\u001b[0m         msg \u001b[39m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[0;32m    860\u001b[0m                             verbose\u001b[39m=\u001b[39mverbose, header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m    861\u001b[0m                             names\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m), precision\u001b[39m=\u001b[39mprecision)\n\u001b[1;32m--> 862\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(msg)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.0001, atol=1e-08\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference: 0.02408938\nMax relative difference: 0.01786572\n x: array(1.324269)\n y: array(1.348358)"
     ]
    }
   ],
   "source": [
    "# we try with SGD\n",
    "w, loss = logistic_regression_SGD(y_log, tx, initial_w, MAX_ITERS, GAMMA)\n",
    "print(loss)\n",
    "print(w)\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test regularized logistic: the function is not working :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\ML_Project_1\\debug.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lambda_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m w, loss \u001b[39m=\u001b[39m reg_logistic_regression_GD(y_log, tx, lambda_, initial_w, MAX_ITERS, GAMMA)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m expected_loss \u001b[39m=\u001b[39m \u001b[39m0.972165\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m expected_w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0.216062\u001b[39m, \u001b[39m0.467747\u001b[39m])\n",
      "File \u001b[1;32mc:\\ML_Project_1\\implementations.py:158\u001b[0m, in \u001b[0;36mreg_logistic_regression_GD\u001b[1;34m(y, tx, initial_w, max_iters, gamma, lambda_)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Regularized logistic regression using GD (y in {0,1},\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mregularization term lambda*||w||^2)\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m    lambda_: regularization parameter\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m w \u001b[39m=\u001b[39m initial_w\n\u001b[1;32m--> 158\u001b[0m \u001b[39mfor\u001b[39;00m n_iter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(max_iters):\n\u001b[0;32m    159\u001b[0m     \u001b[39m# compute gradient\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     grad, _ \u001b[39m=\u001b[39m regularized_logistic_gradient(y, tx, w, lambda_)\n\u001b[0;32m    161\u001b[0m     \u001b[39m# update w by gradient descent\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "lambda_ = 1.0\n",
    "w, loss = reg_logistic_regression_GD(y_log, tx, lambda_, initial_w, MAX_ITERS, GAMMA)\n",
    "expected_loss = 0.972165\n",
    "expected_w = np.array([0.216062, 0.467747])\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\ML_Project_1\\debug.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lambda_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m expected_w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0.409111\u001b[39m, \u001b[39m0.843996\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m w, loss \u001b[39m=\u001b[39m reg_logistic_regression_GD(y, tx, lambda_, expected_w, \u001b[39m0\u001b[39;49m, GAMMA)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m expected_loss \u001b[39m=\u001b[39m \u001b[39m1.407327\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ML_Project_1/debug.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m check_answers(w, loss, expected_w, expected_loss)\n",
      "File \u001b[1;32mc:\\ML_Project_1\\implementations.py:158\u001b[0m, in \u001b[0;36mreg_logistic_regression_GD\u001b[1;34m(y, tx, initial_w, max_iters, gamma, lambda_)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Regularized logistic regression using GD (y in {0,1},\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mregularization term lambda*||w||^2)\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m    lambda_: regularization parameter\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m w \u001b[39m=\u001b[39m initial_w\n\u001b[1;32m--> 158\u001b[0m \u001b[39mfor\u001b[39;00m n_iter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(max_iters):\n\u001b[0;32m    159\u001b[0m     \u001b[39m# compute gradient\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     grad, _ \u001b[39m=\u001b[39m regularized_logistic_gradient(y, tx, w, lambda_)\n\u001b[0;32m    161\u001b[0m     \u001b[39m# update w by gradient descent\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# 0 step\n",
    "lambda_ = 1.0\n",
    "expected_w = np.array([0.409111, 0.843996])\n",
    "w, loss = reg_logistic_regression_GD(y, tx, lambda_, expected_w, 0, GAMMA)\n",
    "expected_loss = 1.407327\n",
    "check_answers(w, loss, expected_w, expected_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
